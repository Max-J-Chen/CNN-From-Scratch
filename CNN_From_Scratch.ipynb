{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XbiAHvAt2CBS",
        "sNcRQ8zHD6RI"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Statements\n"
      ],
      "metadata": {
        "id": "k9pCOEw8HKWR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7-4ErOlaG7Oq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import io\n",
        "import random\n",
        "import zipfile\n",
        "import logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from PIL import Image\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Dataset\n",
        "\n",
        "Link to dataset: https://drive.google.com/drive/folders/1YPuVjC1qK1inVBkVh5teQRVcT8O9wWBH?usp=sharing\n",
        "\n",
        "You must add a shortcut of Archive.zip to your own drive. This can be done by hitting the \"Dataset\" dropdown -> Organize -> Add Shortcut -> My Drive. After the shortcut is added, the following imports will work correctly."
      ],
      "metadata": {
        "id": "r996TKXh2w56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/')\n",
        "\n",
        "# Unzip dataset\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/Dataset/dataset.zip\", 'r')\n",
        "zip_ref.extractall(\"/tmp/dataset\")\n",
        "zip_ref.close()\n",
        "\n",
        "# Initialize empty lists\n",
        "X_original = []\n",
        "Y = []\n",
        "\n",
        "map_labels ={'buildings' : 0, 'forest' : 1, 'glacier' : 2, 'mountain' : 3, 'sea' : 4, 'street' : 5}\n",
        "\n",
        "# Define folder path\n",
        "folder_path = '/tmp/dataset/dataset'\n",
        "\n",
        "# Check if the folder exists\n",
        "if os.path.exists(folder_path):\n",
        "    # Change the current working directory to the \"tmp\" folder\n",
        "    os.chdir(folder_path)\n",
        "else:\n",
        "    print(\"The 'tmp' folder does not exist in your Google Drive.\")\n",
        "\n",
        "# Iterate through main folder to define class labels\n",
        "for label in os.listdir(folder_path):\n",
        "    label_path = os.path.join(folder_path, label)\n",
        "\n",
        "    # Iterate through each subfolder and apply class labels\n",
        "    if os.path.isdir(label_path):\n",
        "        for image_file in os.listdir(label_path):\n",
        "\n",
        "            image_path = os.path.join(label_path, image_file)\n",
        "\n",
        "            img = np.array(cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB))\n",
        "\n",
        "            # Reject any images not 150x150 px\n",
        "            if len(img) != 150: continue\n",
        "\n",
        "            X_original.append(img)\n",
        "\n",
        "            # Append the corresponding label (folder name) to Y_train list\n",
        "            Y.append(map_labels[label])\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X_original = np.array(X_original)\n",
        "Y = np.array(Y)\n"
      ],
      "metadata": {
        "id": "RgTQh44f0Zum",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4de2f9ea-2d7d-4d95-a96b-7b380b7a8e29"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolution Layer Definition\n",
        "\n",
        "The architecture of a standard convolutional layer uses square kernels or filters and a ReLu activation function on the output feature map to introduce non-linearity to the network."
      ],
      "metadata": {
        "id": "HLNEbDzuwCmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvolutionalLayer:\n",
        "\n",
        "    def __init__(self, num_filters, filter_size, stride, padding, input_channels):\n",
        "        self.num_filters = num_filters\n",
        "        self.filter_size = filter_size  # We assume a square filter\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.input_channels = input_channels\n",
        "\n",
        "        # Create random filters with constant normalization\n",
        "        self.filters = np.random.randn(num_filters, filter_size, filter_size, input_channels) / (filter_size ** 2)\n",
        "        self.biases = np.random.randn(1, num_filters) / (filter_size ** 2)\n",
        "\n",
        "    def forward_pass(self, input_image):\n",
        "        # Calculate output_feature_map dimensions\n",
        "        input_height, input_width, _ = input_image.shape\n",
        "        output_height = (input_height - self.filter_size + 2 * self.padding) // self.stride + 1\n",
        "        output_width = (input_width - self.filter_size + 2 * self.padding) // self.stride + 1\n",
        "\n",
        "        # Initialize empty output_feature_map to store results of convolution operations\n",
        "        output_feature_map = np.zeros((output_height, output_width, self.num_filters))\n",
        "\n",
        "        # Pad image to avoid losing\n",
        "        self.padded_input_image = np.pad(input_image, ((self.padding, self.padding), (self.padding, self.padding), (0, 0)), mode='constant')\n",
        "\n",
        "        # Convolve through each of the filters and the dimensions of the padded input image\n",
        "        for f in range(self.num_filters):\n",
        "            for h in range(output_height):\n",
        "                for w in range(output_width):\n",
        "                    # Determine the coordinates of the receptive field\n",
        "                    h_start = h * self.stride\n",
        "                    h_end = h_start + self.filter_size\n",
        "                    w_start = w * self.stride\n",
        "                    w_end = w_start + self.filter_size\n",
        "\n",
        "                    # Calculates the dotproduct of the receptive field with the current filter\n",
        "                    receptive_field = self.padded_input_image[h_start:h_end, w_start:w_end, :]\n",
        "                    output_feature_map[h, w, f] = np.sum(receptive_field * self.filters[f]) + self.biases[0, f]\n",
        "\n",
        "        return output_feature_map\n",
        "\n",
        "    def backward_pass(self, deriv_wrt_output, learning_rate):\n",
        "        # Initialize volume for gradients with respect to the input image with padding\n",
        "        output_height, output_width, _ = deriv_wrt_output.shape\n",
        "        deriv_wrt_padded_input = np.zeros((output_height + 2 * self.padding, output_width + 2 * self.padding, self.input_channels))\n",
        "\n",
        "        # Gradient clipping\n",
        "        max_grad_norm = 1.0  # Define a maximum gradient norm\n",
        "        grad_norm = np.linalg.norm(deriv_wrt_padded_input)\n",
        "        if grad_norm > max_grad_norm:\n",
        "            scale_factor = max_grad_norm / grad_norm\n",
        "            deriv_wrt_padded_input *= scale_factor\n",
        "\n",
        "        # Convolve through each of the filters with the gradients wrt to the output image\n",
        "        for f in range(self.num_filters):\n",
        "            for h in range(output_height):\n",
        "                for w in range(output_width):\n",
        "                    # Determine the coordinates of the receptive field\n",
        "                    h_start = h * self.stride\n",
        "                    h_end = h_start + self.filter_size\n",
        "                    w_start = w * self.stride\n",
        "                    w_end = w_start + self.filter_size\n",
        "\n",
        "                    # Calculate and accumulate the gradient contribution of each input element by convolution of the input image with the loss gradient wrt the output\n",
        "                    deriv_wrt_padded_input[h_start:h_end, w_start:w_end, :] += deriv_wrt_output[h, w, f] * self.filters[f]\n",
        "\n",
        "                    # Calculate the gradient contribution of each filter element by convolution of the input image with the loss gradient wrt the output and update weights\n",
        "                    self.filters[f] -= learning_rate * np.sum(deriv_wrt_output[h, w, f] * self.padded_input_image[h_start:h_end, w_start:w_end, :], axis=(0, 1, 2))\n",
        "                    self.biases[0, f] -= learning_rate * deriv_wrt_output[h, w, f]\n",
        "\n",
        "\n",
        "        # Remove the padding to get gradients for the actual input image\n",
        "        if self.padding > 0:\n",
        "            deriv_wrt_input = deriv_wrt_padded_input[self.padding:-self.padding, self.padding:-self.padding, :]\n",
        "        else:\n",
        "            deriv_wrt_input = deriv_wrt_padded_input\n",
        "\n",
        "        return deriv_wrt_input\n"
      ],
      "metadata": {
        "id": "9OzygfzPpjES"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Layer Demonstration"
      ],
      "metadata": {
        "id": "XbiAHvAt2CBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Common hyper-parameters for a ConvNet Layer is the following\n",
        "conv1 = ConvolutionalLayer(num_filters = 1,\n",
        "                          filter_size = 3,\n",
        "                          stride = 1,\n",
        "                          padding = 1,\n",
        "                          input_channels = 3)\n",
        "\n",
        "print(\"Inputted Image\")\n",
        "output_feature_map = conv1.forward_pass(X_original[1000])\n",
        "plt.imshow(X_original[1000])\n",
        "print(X_original[1000].shape)"
      ],
      "metadata": {
        "id": "zhdjFpPj2CcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Output Feature Map\")\n",
        "plt.imshow(output_feature_map)\n",
        "print(output_feature_map.shape)"
      ],
      "metadata": {
        "id": "Cv-YnCsj2HQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ReLu Layer"
      ],
      "metadata": {
        "id": "x3FQwNVih8dI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLuLayer:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.image = None\n",
        "\n",
        "    def forward_pass(self, image):\n",
        "        self.image = image\n",
        "        # Apply ReLU activation function to the output feature map\n",
        "        return np.maximum(0, image)\n",
        "\n",
        "    def backward_pass(self, deriv_wrt_output):\n",
        "        # Backpropagate gradients through ReLU\n",
        "        deriv_wrt_input = deriv_wrt_output * (self.image > 0)\n",
        "        return deriv_wrt_input"
      ],
      "metadata": {
        "id": "bX0v1-BVh-RH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Max Pooling Layer\n",
        "\n",
        "Note that a pool_size= 2 and stride= 2 will halve the dimensionality of an input image. For example, 150x150x3 will become a 75x75x3."
      ],
      "metadata": {
        "id": "qYhY-gHji0FP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxPoolingLayer:\n",
        "\n",
        "    def __init__(self, pool_size=2, stride=2):\n",
        "        self.pool_size = pool_size  # We assume a square pooling filter\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward_pass(self, input_image):\n",
        "        # Calculate output_feature_map dimensions\n",
        "        input_height, input_width, num_channels = input_image.shape\n",
        "        output_height = (input_height - self.pool_size) // self.stride + 1\n",
        "        output_width = (input_width - self.pool_size) // self.stride + 1\n",
        "        self.image = input_image\n",
        "\n",
        "        # Initialize the empty output_feature_map to store result\n",
        "        output_feature_map = np.zeros((output_height, output_width, num_channels))\n",
        "\n",
        "        # Iterate over each pooling region in each channel\n",
        "        for c in range(num_channels):\n",
        "            for h in range(output_height):\n",
        "                for w in range(output_width):\n",
        "                    # Determine the coordinates of the pooling region\n",
        "                    h_start = h * self.stride\n",
        "                    h_end = h_start + self.pool_size\n",
        "                    w_start = w * self.stride\n",
        "                    w_end = w_start + self.pool_size\n",
        "\n",
        "                    # Extract the pooling region from the input image\n",
        "                    pooling_region = input_image[h_start:h_end, w_start:w_end, c]\n",
        "\n",
        "                    # Apply max pooling to get the maximum value within the pooling region\n",
        "                    output_feature_map[h, w, c] = np.max(pooling_region)\n",
        "\n",
        "        return output_feature_map\n",
        "\n",
        "    def backward_pass(self, deriv_wrt_output):\n",
        "        # Initialize volume for gradients with respect to the input image\n",
        "        input_height, input_width, num_channels = self.image.shape\n",
        "        output_height, output_width, _ = deriv_wrt_output.shape\n",
        "        deriv_wrt_input = np.zeros_like(self.image)\n",
        "\n",
        "        # Loop over each channel and each coordinate in the output feature map, which corresponds to a pooling region in the input feature map\n",
        "        for c in range(num_channels):\n",
        "            for h in range(output_height):\n",
        "                for w in range(output_width):\n",
        "                    # Determine the coordinates of the pooling region\n",
        "                    h_start = h * self.stride\n",
        "                    h_end = h_start + self.pool_size\n",
        "                    w_start = w * self.stride\n",
        "                    w_end = w_start + self.pool_size\n",
        "\n",
        "                    # Extract the local region from the input feature map corresponding to the coordinate in the output feature map (h, w)\n",
        "                    local_region = self.image[h_start:h_end, w_start:w_end, c]\n",
        "\n",
        "                    # Find the h, w coordinates of the maximum value in the local region\n",
        "                    max_pos = np.unravel_index(np.argmax(local_region), local_region.shape)\n",
        "\n",
        "                    # Distribute the gradients to the corresponding position in the input feature map; Every other position does not change\n",
        "                    deriv_wrt_input[h_start + max_pos[0], w_start + max_pos[1], c] = deriv_wrt_output[h, w, c]\n",
        "\n",
        "        return deriv_wrt_input"
      ],
      "metadata": {
        "id": "GWEo_hW2i2r3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Flatten Layer\n"
      ],
      "metadata": {
        "id": "qrgSJ0B7Rd2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlattenLayer:\n",
        "    def __init__(self):\n",
        "        self.input_shape = None\n",
        "\n",
        "    def forward_pass(self, input_data):\n",
        "        self.input_shape = input_data.shape\n",
        "        flattened_output = input_data.reshape(-1)\n",
        "        return flattened_output\n",
        "\n",
        "    def backward_pass(self, d_output_data):\n",
        "        return d_output_data.reshape(self.input_shape)"
      ],
      "metadata": {
        "id": "rlOPvYjfRhDg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fully Connected Layer"
      ],
      "metadata": {
        "id": "h9CL16495Laa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FullyConnectedLayerReLu:\n",
        "\n",
        "    def __init__(self, input_size, output_size):\n",
        "        self.input_size = input_size                # Number of input features (flattened)\n",
        "        self.output_size = output_size              # Number of neurons in the layer for classification.\n",
        "\n",
        "        # Initialize weights and biases with random values\n",
        "        self.weights = np.random.randn(output_size, input_size) * 0.01\n",
        "        self.biases = np.random.randn(output_size) * 0.01\n",
        "\n",
        "    def forward_pass(self, input):\n",
        "        self.input = input\n",
        "\n",
        "        # Calculate raw output net\n",
        "        self.output = np.dot(self.weights, input) + self.biases\n",
        "\n",
        "        # Remember positions where net > 0\n",
        "        self.relu_mask = self.output > 0\n",
        "\n",
        "        # Perform ReLu\n",
        "        self.pred = np.maximum(0, self.output)\n",
        "\n",
        "        return self.pred\n",
        "\n",
        "    def backward_pass(self, deriv_wrt_output, learning_rate):\n",
        "        # Calculate derivatives wrt to net, weight, inputs. D_wrt_bias = deriv_wrt_net\n",
        "        self.deriv_wrt_net = self.relu_mask * deriv_wrt_output.T\n",
        "        self.deriv_wrt_weight = (self.deriv_wrt_net.reshape(-1, 1) * self.input)\n",
        "        self.deriv_wrt_inputs = np.dot(self.weights.T, self.deriv_wrt_net.T)\n",
        "\n",
        "        # Update weights and biases using the gradients\n",
        "        self.weights -= learning_rate * self.deriv_wrt_weight\n",
        "        self.biases -= learning_rate * self.deriv_wrt_net\n",
        "\n",
        "        return self.deriv_wrt_inputs\n",
        "\n",
        "    def relu_derivative(self, x):\n",
        "        return (x > 0).astype(int)\n"
      ],
      "metadata": {
        "id": "M1mW96IzBsYr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fully Connected Layer SoftMax"
      ],
      "metadata": {
        "id": "YyKTvJsxxAQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FullyConnectedLayerSoftMax:\n",
        "\n",
        "    def __init__(self, input_size, output_size):\n",
        "        self.input_size = input_size         # Number of input features (flattened)\n",
        "        self.output_size = output_size       # Number of neurons in the layer for classification.\n",
        "\n",
        "        # Initialize weights and biases with random values\n",
        "        self.weights = np.random.randn(output_size, input_size) * 0.01\n",
        "        self.biases = np.random.randn(output_size) * 0.01\n",
        "\n",
        "    def forward_pass(self, input):\n",
        "        self.input = input\n",
        "\n",
        "        # Calculate raw output\n",
        "        self.output = np.dot(self.weights,self.input) + self.biases\n",
        "\n",
        "        # Perform softmax\n",
        "        self.pred = self.soft_max(self.output)\n",
        "\n",
        "        return self.pred\n",
        "\n",
        "    def backward_pass(self, gradient, learning_rate):\n",
        "        # Calculate derivatives wrt to net, weight, inputs. D_wrt_bias = deriv_wrt_net\n",
        "        self.deriv_wrt_net = gradient\n",
        "        self.deriv_wrt_weights = self.deriv_wrt_net.reshape(-1, 1) * self.input\n",
        "        self.deriv_wrt_inputs = np.dot(self.weights.T, self.deriv_wrt_net)\n",
        "\n",
        "        # Gradient clipping\n",
        "        max_grad_norm = 1.0  # Define a maximum gradient norm\n",
        "        grad_norm = np.linalg.norm(self.deriv_wrt_weights)  # Compute gradient norm\n",
        "        if grad_norm > max_grad_norm:\n",
        "            scale_factor = max_grad_norm / grad_norm\n",
        "            self.deriv_wrt_weights *= scale_factor\n",
        "            self.deriv_wrt_net *= scale_factor\n",
        "\n",
        "        # Update the weights and biases using gradient descent\n",
        "        self.weights -= learning_rate * self.deriv_wrt_weights\n",
        "        self.biases -= learning_rate * self.deriv_wrt_net\n",
        "\n",
        "        return self.deriv_wrt_inputs\n",
        "\n",
        "    def soft_max(self, raw_output):\n",
        "        exponential = np.exp(raw_output)\n",
        "        softmax_output = exponential / np.sum(exponential)\n",
        "        return softmax_output\n",
        "\n",
        "    def cross_entropy(self, true_labels_one_hot):\n",
        "        # Compute the negative log likelihood of the true class probabilities and sum them\n",
        "        loss = -np.sum(true_labels_one_hot * np.log(self.pred + 1e-10))\n",
        "        return loss"
      ],
      "metadata": {
        "id": "BFBTtJcY6YJJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notes\n",
        "\n",
        "We use a Softmax Activation Function as opposed to Sigmoid or Tanh since it is better for multi-class classification problems, where the goal is to assign a probability distribution over multiple classes for each input sample.\n",
        "\n",
        "Loss function is Cross-entropy loss since it performs well with multi-class classification tasks."
      ],
      "metadata": {
        "id": "1hbgCxaP5QFT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calls to Methods"
      ],
      "metadata": {
        "id": "sNcRQ8zHD6RI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full Forward Pass\n"
      ],
      "metadata": {
        "id": "DKtiOA5ldUIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def full_forward_pass(input, layers):\n",
        "  # Scale output between 0 and 1\n",
        "  output = input/255\n",
        "  # Pass output of forward prop to next layer\n",
        "  for layer in layers:\n",
        "        output = layer.forward_pass(output)\n",
        "  return output"
      ],
      "metadata": {
        "id": "XprKBzDXdWPF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full Backward Pass"
      ],
      "metadata": {
        "id": "DQavXJ87eOxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def full_backward_pass(gradient, layers, learning_rate = 0.05):\n",
        "  grade = gradient\n",
        "  # Go backwards through layers\n",
        "  for layer in layers[::-1]:\n",
        "      # If layer is conv or so fullyconnected pass learnrate\n",
        "      if type(layer) == ConvolutionalLayer or type(layer) == FullyConnectedLayerSoftMax or type(layer) == FullyConnectedLayerReLu:\n",
        "          grade = layer.backward_pass(grade, learning_rate)\n",
        "      else:\n",
        "          grade = layer.backward_pass(grade)\n",
        "  return grade"
      ],
      "metadata": {
        "id": "-IDqCNe_eUXx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full Epoch"
      ],
      "metadata": {
        "id": "Pknob2Ypvr-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_epoch(input, label, layers, learning_rate=0.05):\n",
        "    # Forward step\n",
        "    output = full_forward_pass(input, layers)\n",
        "    one_hot_labels = index_to_one_hot(label, 6)\n",
        "\n",
        "    # Initial gradient\n",
        "    gradient = output - np.array(one_hot_labels)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = layers[-1].cross_entropy(one_hot_labels)\n",
        "\n",
        "    # Backprop step\n",
        "    gradient_back = full_backward_pass(gradient, layers, learning_rate)\n",
        "\n",
        "    return loss, output\n",
        "\n",
        "def index_to_one_hot(index, array_size):\n",
        "  one_hot_encoding = [0] * array_size\n",
        "  one_hot_encoding[index] = 1\n",
        "  return one_hot_encoding"
      ],
      "metadata": {
        "id": "kBK4K7kUvsQ2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Model"
      ],
      "metadata": {
        "id": "IVQb9CdkXVcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(X_test, Y_test, layers):\n",
        "\n",
        "    Y_pred = []\n",
        "    avg_loss = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    for i, (image, label) in enumerate(zip(X_test, Y_test)):\n",
        "        # Forward pass\n",
        "        output = full_forward_pass(image, layers)\n",
        "        Y_pred.append(np.argmax(output, axis = None))\n",
        "\n",
        "        # Accumulate total loss\n",
        "        one_hot_labels = index_to_one_hot(label, 6)\n",
        "        total_loss += layers[-1].cross_entropy(one_hot_labels)\n",
        "\n",
        "        if i % 20 == 0:\n",
        "            print(\"Iteration\", i)\n",
        "\n",
        "    avg_loss = total_loss / len(Y_test)\n",
        "\n",
        "    return Y_pred, avg_loss"
      ],
      "metadata": {
        "id": "UCk0krJCXYXd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main\n"
      ],
      "metadata": {
        "id": "-MwAaHzdDPGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Train Split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_original, Y, test_size = .3, random_state=42)\n",
        "\n",
        "# Define model layers\n",
        "layers = [\n",
        "    MaxPoolingLayer(pool_size= 2, stride=2),\n",
        "    ConvolutionalLayer(num_filters = 8,\n",
        "                          filter_size = 3,\n",
        "                          stride = 1,\n",
        "                          padding = 1,\n",
        "                          input_channels = 3),\n",
        "    ReLuLayer(),\n",
        "    ConvolutionalLayer(num_filters = 8,\n",
        "                          filter_size = 3,\n",
        "                          stride = 1,\n",
        "                          padding = 1,\n",
        "                          input_channels = 8),\n",
        "    ReLuLayer(),\n",
        "    MaxPoolingLayer(pool_size= 4, stride=4),\n",
        "    FlattenLayer(),\n",
        "    FullyConnectedLayerReLu(input_size= 2592, output_size= 100),\n",
        "    FullyConnectedLayerReLu(input_size= 100, output_size= 30),\n",
        "    FullyConnectedLayerSoftMax(input_size= 30, output_size = 6),\n",
        "    ]\n",
        "\n",
        "num_correct = 0\n",
        "num_pred = 0\n",
        "loss_sum = 0\n",
        "avg_loss = None\n",
        "\n",
        "# Train Model\n",
        "for epoch in range(1):\n",
        "    for i, (image, label) in enumerate(tqdm(zip(X_train, Y_train), total=len(X_train), ncols=150)):\n",
        "        loss, output = run_epoch(image, label, layers, learning_rate=0.05)\n",
        "\n",
        "        # Track results\n",
        "        prediction = np.argmax(output, axis=None)\n",
        "        num_pred += 1\n",
        "        if label == prediction:\n",
        "            num_correct += 1\n",
        "\n",
        "        accuracy = round(num_correct / num_pred, 3)\n",
        "        loss_sum += loss\n",
        "\n",
        "avg_loss = loss_sum / len(Y_train)\n",
        "print(\"Avg_Training_Loss= \", round(avg_loss, 3), \"Avg_Training_Accuracy= \", accuracy)\n",
        "\n",
        "# Test Model\n",
        "Y_pred = test_model(X_test, Y_test, layers)"
      ],
      "metadata": {
        "id": "5yZKTqCMDOq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output Metrics"
      ],
      "metadata": {
        "id": "wI6vbiPyZFzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the unique labels from the data\n",
        "unique_labels = np.unique(np.concatenate((Y_test, Y_pred)))\n",
        "label_names = ['buildings' , 'forest' , 'glacier' , 'mountain' , 'sea', 'street']\n",
        "\n",
        "# Calculate test statistics\n",
        "test_accuracy = round(accuracy_score(Y_test, Y_pred), 5)\n",
        "test_precision = round(precision_score(Y_test, Y_pred, average = 'macro'), 5)\n",
        "test_recall = round(recall_score(Y_test, Y_pred, average = 'macro'), 5)\n",
        "test_f1 = round(f1_score(Y_test, Y_pred, average = 'macro'), 5)\n",
        "cm = confusion_matrix(Y_test, Y_pred)\n",
        "\n",
        "print(\"Testing Statistics\")\n",
        "print(\"_________________________________________\")\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "print(\"Test Precision:\", test_precision)\n",
        "print(\"Test Recall:\", test_recall)\n",
        "print(\"Test F1:\",test_f1)\n",
        "print(\"Average Test Loss:\", test_avg_loss)\n",
        "\n",
        "# Create the heatmap using seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_names, yticklabels=label_names)\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5kFFXfh1ZPPi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
